{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyM8SlXBHkG3JV8kvUFpyMKf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yckamra/MovieLens25m-Recommender/blob/main/MovieLens_Recommender_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Installing project dependencies...\")\n",
        "!pip install numpy pandas scipy scikit-learn # Basic libraries we want\n",
        "!pip install implicit # Installs implicit library for matrix factorization\n",
        "!pip install torch\n",
        "print(\"Dependencies installed successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32NmVGoMsKJL",
        "outputId": "f2654389-7d24-45be-f9d9-a18e15d16524"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing project dependencies...\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: implicit in /usr/local/lib/python3.11/dist-packages (0.7.2)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from implicit) (2.0.2)\n",
            "Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.11/dist-packages (from implicit) (1.15.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from implicit) (4.67.1)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.11/dist-packages (from implicit) (3.6.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Dependencies installed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GbhcESHldBDk"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from scipy.sparse import coo_matrix, csr_matrix # Compressed Sparse Row"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "\n",
        "!gcloud config set project movielens-recommender-451017\n",
        "\n",
        "!gsutil cp gs://movielens-data/movielens_data.zip /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etCajMZSdIE6",
        "outputId": "7249c950-ec06-4259-98e7-3470dd948c4c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n",
            "Copying gs://movielens-data/movielens_data.zip...\n",
            "==> NOTE: You are downloading one or more large file(s), which would\n",
            "run significantly faster if you enabled sliced object downloads. This\n",
            "feature is enabled by default but requires that compiled crcmod be\n",
            "installed (see \"gsutil help crcmod\").\n",
            "\n",
            "/ [1 files][257.5 MiB/257.5 MiB]   23.2 MiB/s                                   \n",
            "Operation completed over 1 objects/257.5 MiB.                                    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset can be found at: https://www.kaggle.com/datasets/garymk/movielens-25m-dataset"
      ],
      "metadata": {
        "id": "IguZS0cTdR_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRjv3UhAdKU9",
        "outputId": "f508d5ea-1ed0-4d51-f1b9-34e16e19842f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 258M\n",
            "drwxr-xr-x 3 root root 4.0K May 24 17:59 data\n",
            "-rw-r--r-- 1 root root 258M May 24 19:30 movielens_data.zip\n",
            "drwxr-xr-x 1 root root 4.0K May 14 13:38 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path = \"/content/movielens_data.zip\"  # Change to your actual zip file name\n",
        "extract_to = \"/content/data/\"  # Where to extract files\n",
        "\n",
        "# Create directory if it doesn't exist\n",
        "os.makedirs(extract_to, exist_ok=True)\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "print(\"Extraction complete! Files are in:\", extract_to)\n",
        "!ls -lh /content/data/ml-25m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwv85jWDdS2x",
        "outputId": "3f867928-a19a-4c4c-8121-c57974ac72fb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction complete! Files are in: /content/data/\n",
            "total 1.1G\n",
            "-rw-r--r-- 1 root root 416M May 24 19:30 genome-scores.csv\n",
            "-rw-r--r-- 1 root root  18K May 24 19:30 genome-tags.csv\n",
            "-rw-r--r-- 1 root root 1.4M May 24 19:30 links.csv\n",
            "-rw-r--r-- 1 root root 2.9M May 24 19:30 movies.csv\n",
            "-rw-r--r-- 1 root root 647M May 24 19:30 ratings.csv\n",
            "-rw-r--r-- 1 root root  11K May 24 19:30 README.txt\n",
            "-rw-r--r-- 1 root root  38M May 24 19:30 tags.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "genome_scores_CSV = \"/content/data/ml-25m/genome-scores.csv\"\n",
        "genome_tags_CSV = \"/content/data/ml-25m/genome-tags.csv\"\n",
        "links_CSV = \"/content/data/ml-25m/links.csv\"\n",
        "movies_CSV = \"/content/data/ml-25m/movies.csv\"\n",
        "ratings_CSV = \"/content/data/ml-25m/ratings.csv\"\n",
        "tags_CSV = \"/content/data/ml-25m/tags.csv\""
      ],
      "metadata": {
        "id": "mjxVguVKdZTB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ratings.csv provides us with the data needed for the context-based recommender"
      ],
      "metadata": {
        "id": "o32mQB5ne-Qy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ratings data\n",
        "ratings_path = ratings_CSV\n",
        "ratings_df = pd.read_csv(ratings_path)\n",
        "\n",
        "print(ratings_df.head())\n",
        "\n",
        "# Sort by user\n",
        "ratings_df.sort_values('userId', inplace=True, ignore_index=True)\n",
        "\n",
        "# Count unique users and movies\n",
        "num_users = ratings_df[\"userId\"].nunique()\n",
        "num_movies = ratings_df[\"movieId\"].nunique()\n",
        "\n",
        "print(f\"Number of Unique Users: {num_users}\")\n",
        "print(f\"Number of Unique Movies: {num_movies}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuhhQSuudbqr",
        "outputId": "37087c97-0a21-40e2-f5bf-346c41ddb81b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   userId  movieId  rating   timestamp\n",
            "0       1      296     5.0  1147880044\n",
            "1       1      306     3.5  1147868817\n",
            "2       1      307     5.0  1147868828\n",
            "3       1      665     5.0  1147878820\n",
            "4       1      899     3.5  1147868510\n",
            "Number of Unique Users: 162541\n",
            "Number of Unique Movies: 59047\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be using collaborative filtering for recommendations. A 2D matrix will be created for movie to user ratings with movies on x-axis and users on y-axis. For new users, we ask for a baseline amount of movies to get a starting vector, and then we use cosine similarity to find their similarity to existing users to recommend them movies. With more ratings, comes greater accuracy."
      ],
      "metadata": {
        "id": "fYfXiDXLsOpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#numpy_matrix = np.zeros((num_users, num_movies))\n",
        "#print(numpy_matrix)\n",
        "#print(numpy_matrix.shape)"
      ],
      "metadata": {
        "id": "oZBQruTBddqK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to map IDs of movies and users to the 2D matrix for collaborative filtering, we will use dictionaries to create key-value pairs between ID and index within the matrix."
      ],
      "metadata": {
        "id": "0NWMoOVuHJbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_id_map = {}\n",
        "movie_id_map = {}\n",
        "user_index = 0\n",
        "movie_index = 0\n",
        "\n",
        "# Create user_id and movie_id to 2D matrix indices\n",
        "for user in ratings_df[\"userId\"]: # Use this for sparse matrix, not userId since users could be removed from dataset\n",
        "  if user not in user_id_map:\n",
        "    user_id_map[user] = user_index\n",
        "    user_index += 1\n",
        "\n",
        "for movie in ratings_df[\"movieId\"]:\n",
        "  if movie not in movie_id_map:\n",
        "    movie_id_map[movie] = movie_index\n",
        "    movie_index += 1"
      ],
      "metadata": {
        "id": "Hkh0j1qPvVhT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice below that we are populating a dense matrix, so if we have ~25 million cells to populate out of the ~9 billion from our 162,541 x 59047 matrix filled with zeroes, we are dealing with major sparcity problems and wasted memory. So below is just to later enjoy shorter train times and smaller matrices. Going forward we will be using a Compressed Sparse Row matrix. This will help in learning user and movie abstract feature matrices and cosine similarities."
      ],
      "metadata": {
        "id": "C3cgm5PCyWA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from IPython.display import clear_output\n",
        "\n",
        "#iter = 0\n",
        "#percent_done = 0\n",
        "#total_rows = len(ratings_df)\n",
        "# Iterate over the rows of the DataFrame\n",
        "#for index, row in ratings_df.iterrows():\n",
        "    #user_index = user_id_map[row[\"userId\"]]\n",
        "    #movie_index = movie_id_map[row[\"movieId\"]]\n",
        "    #numpy_matrix[user_index, movie_index] = row[\"rating\"]\n",
        "    #if iter % int(total_rows / 100) == 0:\n",
        "      #clear_output(wait=True)\n",
        "      #print(f\"Percent of matrix populated with ratings: {percent_done}%\")\n",
        "      #percent_done += 1\n",
        "    #iter += 1"
      ],
      "metadata": {
        "id": "zexX8aolyMeE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ratings_dataframe = pd.DataFrame(numpy_matrix)\n",
        "#print(ratings_dataframe.head())"
      ],
      "metadata": {
        "id": "KIgSo8-gLyAY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparing the dataframe ratings to the original Kaggle dataset\n",
        "#print(f\"Original Rating: 4.0 Found Rating: {ratings_dataframe.loc[user_id_map[1], movie_id_map[8786]]}\")\n",
        "#print(f\"Original Rating: 2.0 Found Rating: {ratings_dataframe.loc[user_id_map[2], movie_id_map[480]]}\")\n",
        "#print(f\"Original Rating: 3.5 Found Rating: {ratings_dataframe.loc[user_id_map[3], movie_id_map[1270]]}\")\n",
        "#print(ratings_dataframe.shape)"
      ],
      "metadata": {
        "id": "QhE8yl1AedIi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I have created my own arrays for sparse matrix. We will use scipy in order to have more accurate conversions, but this gives us another option and removes the blackbox."
      ],
      "metadata": {
        "id": "w3TYULQMb50u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_data_array(df):  # Numpy array of ratings\n",
        "  ratings_df = df\n",
        "  data = ratings_df[\"rating\"].to_numpy()\n",
        "  print(data)\n",
        "  return data\n",
        "\n",
        "def calculate_movie_indices(df):   # Numpy array of movie indices\n",
        "  ratings_df = df\n",
        "  indices = ratings_df[\"movieId\"].to_numpy()\n",
        "\n",
        "  for i in range(len(indices)):\n",
        "      indices[i] = movie_id_map[int(indices[i])]\n",
        "  print(indices)\n",
        "  return indices\n",
        "\n",
        "\n",
        "def calculate_indptr(df):   # Numpy array of pointers to indices\n",
        "  ratings_df = df\n",
        "  num_users = ratings_df[\"userId\"].nunique()\n",
        "  indptr = np.zeros(num_users + 1, dtype=int)\n",
        "  last_user = ratings_df[\"userId\"].iloc[0]\n",
        "  index_in_indptr = 1\n",
        "  iterator = 0\n",
        "\n",
        "  for i in range(len(ratings_df[\"userId\"])):\n",
        "    current_user = ratings_df[\"userId\"].iloc[iterator]\n",
        "    if current_user != last_user:\n",
        "      indptr[index_in_indptr] = iterator\n",
        "      index_in_indptr += 1\n",
        "      last_user = current_user\n",
        "    iterator += 1\n",
        "\n",
        "  indptr[index_in_indptr] = len(ratings_df[\"userId\"]) # This fills up the last indice\n",
        "\n",
        "  print(indptr)\n",
        "  return indptr\n",
        "\n",
        "#data = {'userId': [0, 0, 1, 2, 2, 2, 3]} # For testing\n",
        "#df = pd.DataFrame(data) # For testing\n",
        "#calculate_indptr(df) # For testing"
      ],
      "metadata": {
        "id": "U9Q3wmWtn9Bp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the maps to the DataFrame columns to get the 0-indexed row and column arrays\n",
        "row_indices = ratings_df['userId'].map(user_id_map).to_numpy()\n",
        "col_indices = ratings_df['movieId'].map(movie_id_map).to_numpy()\n",
        "data_values = ratings_df['rating'].to_numpy() # The actual ratings\n",
        "\n",
        "# Create the COO (Coordinate) Matrix\n",
        "user_item_matrix_coo = coo_matrix(\n",
        "    (data_values, (row_indices, col_indices)),\n",
        "    shape=(num_users, num_movies)\n",
        ")\n",
        "\n",
        "# Convert to CSR (Compressed Sparse Row) for efficient operations. Gets the `indptr` array and sorts `indices`\n",
        "user_item_matrix_csr = user_item_matrix_coo.tocsr()"
      ],
      "metadata": {
        "id": "lECsL1DKqOtD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice below that the indice array is different than our function. This is because although the user indice array is sorted as the main sort, within each user's range--the subsection for each user--has their movie indices sorted as well."
      ],
      "metadata": {
        "id": "InSo2U69ezXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Converted to CSR Matrix.\")\n",
        "print(\"CSR Shape:\", user_item_matrix_csr.shape)\n",
        "print(\"CSR data:\", user_item_matrix_csr.data)\n",
        "print(\"CSR indices (column indices):\", user_item_matrix_csr.indices)\n",
        "print(\"CSR indptr (pointers to row starts):\", user_item_matrix_csr.indptr)"
      ],
      "metadata": {
        "id": "zv2NovANwXVa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a263d6f-6c73-41ef-e4e8-92063d0665c0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted to CSR Matrix.\n",
            "CSR Shape: (162541, 59047)\n",
            "CSR data: [5.  3.5 4.  ... 2.  3.  2.5]\n",
            "CSR indices (column indices): [    0     1     2 ... 12315 12777 14125]\n",
            "CSR indptr (pointers to row starts): [       0       70      254 ... 24999825 24999913 25000095]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def get_cosine_similarity_userX_to_allUsers(userId, user_id_map, user_item_matrix_csr):\n",
        "  user_index = user_id_map[userId]\n",
        "  target_user_vector = user_item_matrix_csr[user_index : user_index + 1]\n",
        "  return cosine_similarity(target_user_vector, user_item_matrix_csr)"
      ],
      "metadata": {
        "id": "Wp0ybBYsdnDB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_cosine_similarity_userX_to_allUsers(1, user_id_map, user_item_matrix_csr))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6XgiHQGvbvy",
        "outputId": "02b64590-2dac-44c5-db46-b6111c1cd162"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.         0.04086293 0.06130627 ... 0.01936879 0.04149169 0.07084903]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_b6cRiIBx0Vj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}