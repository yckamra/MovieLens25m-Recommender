{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOWjjV0Ia/aT2Qt3obYk+36",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yckamra/MovieLens25m-Recommender/blob/main/User_Dictionary_Creation_vFinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PY2APlc8Tv69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "880fc21d-aea0-465e-cd6d-09f02e1f10c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing project dependencies...\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Collecting implicit\n",
            "  Downloading implicit-0.7.2-cp311-cp311-manylinux2014_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from implicit) (2.0.2)\n",
            "Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.11/dist-packages (from implicit) (1.15.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from implicit) (4.67.1)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.11/dist-packages (from implicit) (3.6.0)\n",
            "Downloading implicit-0.7.2-cp311-cp311-manylinux2014_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: implicit\n",
            "Successfully installed implicit-0.7.2\n",
            "Dependencies installed successfully.\n"
          ]
        }
      ],
      "source": [
        "print(\"Installing project dependencies...\")\n",
        "!pip install numpy pandas scipy scikit-learn # Basic libraries we want\n",
        "!pip install implicit # Installs implicit library for matrix factorization\n",
        "#!pip install torch\n",
        "print(\"Dependencies installed successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "from google.cloud import storage\n",
        "import zipfile\n",
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import implicit\n",
        "import json"
      ],
      "metadata": {
        "id": "JnjMV0haT9Ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "\n",
        "!gcloud config set project movielens-recommender-451017\n",
        "\n",
        "!gsutil cp gs://movielens-data/data.zip /content/"
      ],
      "metadata": {
        "id": "8fYy0RB9T_7t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2a93794-5611-4252-bae8-8761281a6ec1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n",
            "Copying gs://movielens-data/data.zip...\n",
            "==> NOTE: You are downloading one or more large file(s), which would\n",
            "run significantly faster if you enabled sliced object downloads. This\n",
            "feature is enabled by default but requires that compiled crcmod be\n",
            "installed (see \"gsutil help crcmod\").\n",
            "\n",
            "- [1 files][262.6 MiB/262.6 MiB]                                                \n",
            "Operation completed over 1 objects/262.6 MiB.                                    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TMDb dataset: https://www.kaggle.com/datasets/tmdb/tmdb-movie-metadata?select=tmdb_5000_movies.csv\n",
        "\n",
        "Big TMDB dataset: https://www.kaggle.com/datasets/asaniczka/tmdb-movies-dataset-2023-930k-movies/data\n",
        "\n",
        "MovieLens dataset: https://www.kaggle.com/datasets/garymk/movielens-25m-dataset"
      ],
      "metadata": {
        "id": "p7XnsK3BUGoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content/"
      ],
      "metadata": {
        "id": "M1tA_ZbAUEL0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6928ef2-2906-4e51-a0c7-1a0f6639d321"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 263M\n",
            "-rw-r--r-- 1 root root 263M Jun 23 21:30 data.zip\n",
            "drwxr-xr-x 1 root root 4.0K Jun 20 13:38 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path = \"/content/data.zip\" # File name\n",
        "extract_to = \"/content/data/\"  # Where to extract files\n",
        "\n",
        "# Create directory if it doesn't exist\n",
        "os.makedirs(extract_to, exist_ok=True)\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "print(\"Extraction complete! Files are in:\", extract_to)\n",
        "!ls -lh /content/data/"
      ],
      "metadata": {
        "id": "URK0MAwzUJfK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8e9cf68-4dc6-4abb-e312-5ee1f980a6ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction complete! Files are in: /content/data/\n",
            "total 8.0K\n",
            "drwxr-xr-x 4 root root 4.0K Jun 23 21:30 data\n",
            "drwxr-xr-x 3 root root 4.0K Jun 23 21:30 __MACOSX\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content/data/data/ml-25m"
      ],
      "metadata": {
        "id": "a29eVT5_UMMT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5644aaa-ff8f-40de-d034-cdc39509d787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1.1G\n",
            "-rw-r--r-- 1 root root 416M Jun 23 21:30 genome-scores.csv\n",
            "-rw-r--r-- 1 root root  18K Jun 23 21:30 genome-tags.csv\n",
            "-rw-r--r-- 1 root root 1.4M Jun 23 21:30 links.csv\n",
            "-rw-r--r-- 1 root root 2.9M Jun 23 21:30 movies.csv\n",
            "-rw-r--r-- 1 root root 647M Jun 23 21:30 ratings.csv\n",
            "-rw-r--r-- 1 root root  11K Jun 23 21:30 README.txt\n",
            "-rw-r--r-- 1 root root  38M Jun 23 21:30 tags.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "genome_scores_CSV = \"/content/data/data/ml-25m/genome-scores.csv\"\n",
        "genome_tags_CSV = \"/content/data/data/ml-25m/genome-tags.csv\"\n",
        "links_CSV = \"/content/data/data/ml-25m/links.csv\"\n",
        "movies_CSV = \"/content/data/data/ml-25m/movies.csv\"\n",
        "ratings_CSV = \"/content/data/data/ml-25m/ratings.csv\"\n",
        "tags_CSV = \"/content/data/data/ml-25m/tags.csv\""
      ],
      "metadata": {
        "id": "4jrKanjjUQpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ratings data\n",
        "ratings_path = ratings_CSV\n",
        "ratings_df = pd.read_csv(ratings_path)\n",
        "\n",
        "print(ratings_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gf0S5unJlZm1",
        "outputId": "9c163154-f94b-4d3d-a2ef-ef6710920dad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          userId  movieId  rating   timestamp\n",
            "0              1      296     5.0  1147880044\n",
            "1              1      306     3.5  1147868817\n",
            "2              1      307     5.0  1147868828\n",
            "3              1      665     5.0  1147878820\n",
            "4              1      899     3.5  1147868510\n",
            "...          ...      ...     ...         ...\n",
            "25000090  162541    50872     4.5  1240953372\n",
            "25000091  162541    55768     2.5  1240951998\n",
            "25000092  162541    56176     2.0  1240950697\n",
            "25000093  162541    58559     4.0  1240953434\n",
            "25000094  162541    63876     5.0  1240952515\n",
            "\n",
            "[25000095 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class User:\n",
        "  # ---Items in self---\n",
        "  # userId : ID in MovieLens 25m dataset\n",
        "  # ratings_df : pandas dataframe containing the users rows within the MovieLens 25m ratings.csv\n",
        "\n",
        "  def __init__(self, userID=None, ratings_df=None):\n",
        "    self.userID = userID\n",
        "    self.ratings_df = ratings_df if ratings_df is not None else pd.DataFrame()\n",
        "\n",
        "  def get_userID(self):\n",
        "    return self.userID\n",
        "\n",
        "  def set_userID(self, ID : int):\n",
        "    assert isinstance(ID, int), \"ID must be an integer\"\n",
        "    self.userID = int(ID)\n",
        "\n",
        "  def add_row_to_ratings_df(self, row):\n",
        "\n",
        "    if row[\"movieId\"] in self.ratings_df[\"movieId\"].values:\n",
        "      return False\n",
        "    else:\n",
        "      self.ratings_df = pd.concat([self.ratings_df, pd.DataFrame([row])], ignore_index=True)\n",
        "\n",
        "    return\n",
        "\n",
        "  def get_sorted_movies(self, rating_threshold): # Returns Users movies with popularity in descending order, rating_threshold only includes ratings above or equal to the threshold\n",
        "    filtered_df = self.ratings_df[self.ratings_df['rating'] >= rating_threshold]\n",
        "    sorted_df = filtered_df.sort_values(by='rating', ascending=False)\n",
        "\n",
        "    df_list = list(sorted_df[\"movieId\"])\n",
        "\n",
        "    return df_list\n",
        "\n",
        "def create_all_users_dictionary(ratings_df):\n",
        "  allUsers = {}\n",
        "  grouped = ratings_df.groupby(\"userId\")\n",
        "\n",
        "  for userId, group in grouped:\n",
        "    user = User(userID=userId, ratings_df=group.copy())  # Store the group slice directly\n",
        "    allUsers[userId] = user\n",
        "\n",
        "  return allUsers\n",
        "\n",
        "allUsers = create_all_users_dictionary(ratings_df)"
      ],
      "metadata": {
        "id": "0iS6irWUUUVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(allUsers[1].ratings_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a9wB0LSTs7E",
        "outputId": "8df84008-6168-4ecc-d96e-bdc0f7853fe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   userId  movieId  rating   timestamp\n",
            "0       1      296     5.0  1147880044\n",
            "1       1      306     3.5  1147868817\n",
            "2       1      307     5.0  1147868828\n",
            "3       1      665     5.0  1147878820\n",
            "4       1      899     3.5  1147868510\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving dictionary to .plk pickle format\n",
        "file_path = 'allUsers_data.pkl'\n",
        "with open(file_path, 'wb') as f: # 'wb' means write in binary mode\n",
        "    pickle.dump(allUsers, f)\n",
        "print(f\"User dictionary saved to {file_path}\")\n",
        "\n",
        "# Loading pickle file\n",
        "with open(file_path, 'rb') as f: # 'rb' means read in binary mode\n",
        "    allUsers = pickle.load(f)\n",
        "print(f\"\\nUser dictionary loaded from {file_path}\")\n",
        "\n",
        "# Verify loaded data\n",
        "print(f\"Loaded user '1' ratings_df: {allUsers[1].ratings_df.head()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHH8Ps-uwuII",
        "outputId": "ef4bfa2f-c8d7-43de-a60c-22d5db45c0fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User dictionary saved to allUsers_data.pkl\n",
            "\n",
            "User dictionary loaded from allUsers_data.pkl\n",
            "Loaded user '1' ratings_df:    userId  movieId  rating   timestamp\n",
            "0       1      296     5.0  1147880044\n",
            "1       1      306     3.5  1147868817\n",
            "2       1      307     5.0  1147868828\n",
            "3       1      665     5.0  1147878820\n",
            "4       1      899     3.5  1147868510\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import storage\n",
        "def save_dict_to_gcs(dictionary_to_save: dict, bucket_name: str, destination_blob_name: str):\n",
        "    try:\n",
        "        auth.authenticate_user()\n",
        "        print(\"Authenticated to Google Cloud.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Could not authenticate user (may be running outside Colab or already authenticated): {e}\")\n",
        "\n",
        "    client = storage.Client()\n",
        "    bucket = client.bucket(bucket_name)\n",
        "    blob = bucket.blob(destination_blob_name)\n",
        "\n",
        "    # Pickle the dictionary into a bytes object\n",
        "    pickled_data = pickle.dumps(dictionary_to_save)\n",
        "\n",
        "    # Upload the bytes object to GCS\n",
        "    # 'upload_from_string' will overwrite if the blob exists, or create it if new.\n",
        "    blob.upload_from_string(pickled_data, content_type='application/octet-stream')\n",
        "\n",
        "    print(f\"Dictionary successfully saved to gs://{bucket_name}/{destination_blob_name}\")"
      ],
      "metadata": {
        "id": "80Icz87HxJsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bucket_name = \"movielens-data\"\n",
        "blob_name = \"allUsers_data.pkl\"\n",
        "save_dict_to_gcs(allUsers, bucket_name, blob_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zM0crvWuxs8H",
        "outputId": "24a2be52-924d-417a-de40-9fa1c5fc9f8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authenticated to Google Cloud.\n",
            "Dictionary successfully saved to gs://movielens-data/allUsers_data.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gy-9d1rwxxL4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}